{
  "hash": "b989cd2028a8c63098a5d8b35136699a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"\"  \nsubtitle: \"\"\nauthor: \"Dean Marchiori\"\ndate: \"2025-01-24\"\ncategories: [survival, analysis]\nimage: \"featured.png\"\neditor_options: \n  chunk_output_type: console\nexecute: \n  echo: false\n  warning: false \n  message: false\n---  \n\n::: {.cell}\n\n:::\n\n\n- what is the problem\n\nThe use of classiciation algorithms to model binary response data are so ubiquitous there \nis a significant risk that in some settings this type of model is inappropriate. \n\nIn many cases the response variable shouldnt\nbe dichotomoised into an event/non-event occurence but instead view non-event as censored \ndata. In effect, an event can either occur, or it is viewed to have not yet occurred (but may\noccur in the future). This inclusion of a temporal dimension allows the model to more\naccurately deal with cases when subjects can drop-out or non experience the response\ncondition during the analysis period. Typical classification algorthms (think logistic\nregression) has to assume we only case about the response at the end of the study period\nand sweep under the rug and time-to-event information. \n\nThis framework is known as survival analysis or time-to-event modelling. It's commonly\napplied in biostaticial settings but is thoroughly un-sexy and I have discovered not\neven in the repertoir for many 'non-statistical' data scientists. \n\nThis is a small field guide with pearls and pitfalls for modelling time-to-event data. \n\n\n## main categories of survival models\n\nThere are three main categories of survival models\n\n1. Non-Parametric: Most commonly the Kaplan-Meier estimator where no assumptions are imposed on either the shape of the survival function nor on the form of the relation ship between predictor variables and survival time.     \n\n\n2. Semi-Parametric: The standard approach here is the Cox Proportional HAzards Model (PH Model). The hazard function gives the instantaneous potential of having an event at a time, given survival up to that time. It is used primarily as a diagnostic\ntool or for specifying a mathematical model for survival analysis. A functional form for covariates is specified to model the hazard curve, but no distributional assumptions are made about the survival times or baseline hazard function. This effectively results in a model that scales a 'baseline' hazard function that is never actually estimated, hence the model being a 'proportional hazards' model and using only a partial-maximum likelihood estimation method.  \n\n\n3. Parametric: Fully parametic models exist and rely on the analyst specifying the functional form of the survival curve (exponential, lognormal etc). I won't wade into these waters on this post. \n\n## Workflows  \n\n- A recommended workflow is to start by using a non-parametric approach such as the\nKaplan-Meier estimator as a descriptive tool. For between group comparisons the \nLog-rank test is the typical standard.  \n\n- Next, a Cox-Proportional Hazards model is a safe choice to enable the inclusion\nof covariates of interest.  \n\n- A Cox PH model will be not suitable to quantify the underlying baseline hazard but has good\nproperties for interpreting and testing hazard ratios from the model's coeeficients (essentially\nan anology to odds ratios in logisitic regression).  \n\n- If the diagnostic tests indicate a poor fit, an alternative model should be tried. If\nthis is from class of parametric survival models, some knowledge and testing of the \ndistribution will be required as an explicit input.   \n\n- Other more exotic model types exist and can be used but typically these are only\ndone with strong justification and are much less common. \n\n\n\n```{mermaid}\nflowchart TD\n  A[(survival data)] --> B[Kaplan-Meier Estimator]\n  B --> C[Log Rank Test]  \n  C --> D[Cox Proportional Hazards Model]\n  C -.-> E[Fully parametric model]  \n  C -.-> F[AFT, other exotic..]\n  style D fill:#f9f\n```\n\n\n  A[Hard edge] --> B(Round edge)\n  B --> C{Decision}\n  C --> D[Result one]\n  C -> E[Result two]\n\n\n## Assumptions  \n\n1. Proportional Hazards: Across time the relative hazard remains constant across covariate levels. This\nhypothesis can be tested using the scaled Schoenfeld residuals. It can also be visually examined using a log(-log(survival)) plot. If a PH model is valid, a plot of the logarithm of the cumulative hazard function in each group against the\nlogarithm of time should give rise to lines that are parallel.\n\n2. Sample size: A heuristic exists that there shoul dbe at least 10 events observed for each covariate considered. \n\n3. Non-Informative Censoring:  While this class of model is designed to handle censored data, the cause \nof censoring should be unrelated to the response and be entirely non-informative. \n\n\n## Diagnostics   \n\n- Goodness of fit can be evaluated visually by comparing the Kaplan-Meirer curve to the \nmodel-based predicted survival. \n\n- Cox-Snell residuals can be used to visually inspect goodness-of-fit\n\n- Interpretation\n\n- Good texts\n\n- Good Packages  \n\n- Lunk to workflow  \n\n\n\n\n\n\n\n>**Want to read more? Sign up to my mailing list [here](https://www.deanmarchiori.com/posts/) for occasional emails and no spam.**  \n> **Looking for a data science consultant? Feel free to [get in touch here](https://www.deanmarchiori.com)**",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}